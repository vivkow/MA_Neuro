{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import re\n",
    "#import numpy as np\n",
    "#import matplotlib as mpl\n",
    "\n",
    "# Fonts for plots\n",
    "#mpl.rcParams['font.serif'] = 'Times New Roman'\n",
    "#plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Path to data retrieval and storage\n",
    "path = \"C:/Users/kleinow/ownCloud/MA_Neuro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>author_seq_nr</th>\n",
       "      <th>aff_seq_nr</th>\n",
       "      <th>organization</th>\n",
       "      <th>wos_suborganization</th>\n",
       "      <th>vendor_org_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOS:000209165300094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"Univ Manchester\"}</td>\n",
       "      <td>{\"Neurosci &amp; Psychiat Unit\"}</td>\n",
       "      <td>{\"University of Manchester\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOS:000209165300094</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"Univ Durham\"}</td>\n",
       "      <td>{\"Dept Psychol\"}</td>\n",
       "      <td>{\"Durham University\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOS:000209204100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"Griffith Univ\"}</td>\n",
       "      <td>{\"Inst Integrated &amp; Intelligent Syst\"}</td>\n",
       "      <td>{\"Griffith University\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOS:000209204100004</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"Griffith Univ\"}</td>\n",
       "      <td>{\"Sch Informat &amp; Commun Technol\"}</td>\n",
       "      <td>{\"Griffith University\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WOS:000209529000006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"Tsinghua Univ\"}</td>\n",
       "      <td>{\"Dept Comp Sci &amp; Technol\",\"Tsinghua Natl Lab ...</td>\n",
       "      <td>{\"Tsinghua University\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id  author_seq_nr  aff_seq_nr         organization  \\\n",
       "0  WOS:000209165300094              1           1  {\"Univ Manchester\"}   \n",
       "1  WOS:000209165300094              2           2      {\"Univ Durham\"}   \n",
       "2  WOS:000209204100004              1           1    {\"Griffith Univ\"}   \n",
       "3  WOS:000209204100004              2           2    {\"Griffith Univ\"}   \n",
       "4  WOS:000209529000006              1           1    {\"Tsinghua Univ\"}   \n",
       "\n",
       "                                 wos_suborganization  \\\n",
       "0                       {\"Neurosci & Psychiat Unit\"}   \n",
       "1                                   {\"Dept Psychol\"}   \n",
       "2             {\"Inst Integrated & Intelligent Syst\"}   \n",
       "3                  {\"Sch Informat & Commun Technol\"}   \n",
       "4  {\"Dept Comp Sci & Technol\",\"Tsinghua Natl Lab ...   \n",
       "\n",
       "                  vendor_org_id  \n",
       "0  {\"University of Manchester\"}  \n",
       "1         {\"Durham University\"}  \n",
       "2       {\"Griffith University\"}  \n",
       "3       {\"Griffith University\"}  \n",
       "4       {\"Tsinghua University\"}  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_articles = pd.read_csv(path + \"/cn_items_clean.csv\") # For article IDs and titles, if needed for reassurance while cleaning\n",
    "df_auth = pd.read_csv(path + \"/cn_authors.csv\")\n",
    "df_auth_aff = pd.read_csv(path + \"/cn_authors_affil.csv\")\n",
    "\n",
    "\n",
    "df_auth_aff.head()\n",
    "#df_auth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging of the two dataframes to combine information about authors and their affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>author_seq_nr</th>\n",
       "      <th>given_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>scopus_alt_script_name</th>\n",
       "      <th>email</th>\n",
       "      <th>corresponding</th>\n",
       "      <th>scopus_author_id</th>\n",
       "      <th>orcid</th>\n",
       "      <th>aff_seq_nr</th>\n",
       "      <th>organization</th>\n",
       "      <th>wos_suborganization</th>\n",
       "      <th>vendor_org_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>1</td>\n",
       "      <td>JL</td>\n",
       "      <td>Krichmar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>2</td>\n",
       "      <td>GA</td>\n",
       "      <td>Ascoli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>3</td>\n",
       "      <td>JL</td>\n",
       "      <td>Olds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "      <td>Bickle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id  author_seq_nr given_name family_name  \\\n",
       "0  WOS:000075569500101              1         JL    Krichmar   \n",
       "1  WOS:000075569500101              2         GA      Ascoli   \n",
       "2  WOS:000075569500101              3         JL        Olds   \n",
       "3  WOS:000075569500101              4          L      Hunter   \n",
       "4  WOS:000086279300008              1          J      Bickle   \n",
       "\n",
       "   scopus_alt_script_name email  corresponding  scopus_author_id orcid  \\\n",
       "0                     NaN   NaN           True               NaN   NaN   \n",
       "1                     NaN   NaN          False               NaN   NaN   \n",
       "2                     NaN   NaN          False               NaN   NaN   \n",
       "3                     NaN   NaN          False               NaN   NaN   \n",
       "4                     NaN   NaN           True               NaN   NaN   \n",
       "\n",
       "   aff_seq_nr organization wos_suborganization vendor_org_id  \n",
       "0         NaN          NaN                 NaN           NaN  \n",
       "1         NaN          NaN                 NaN           NaN  \n",
       "2         NaN          NaN                 NaN           NaN  \n",
       "3         NaN          NaN                 NaN           NaN  \n",
       "4         NaN          NaN                 NaN           NaN  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "df_authors = pd.merge(df_auth, df_auth_aff, how='left', on=['item_id', 'author_seq_nr'])\n",
    "\n",
    "df_authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that do not hold any useful information for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>author_seq_nr</th>\n",
       "      <th>given_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>corresponding</th>\n",
       "      <th>aff_seq_nr</th>\n",
       "      <th>organization</th>\n",
       "      <th>wos_suborganization</th>\n",
       "      <th>vendor_org_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>1</td>\n",
       "      <td>JL</td>\n",
       "      <td>Krichmar</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>2</td>\n",
       "      <td>GA</td>\n",
       "      <td>Ascoli</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>3</td>\n",
       "      <td>JL</td>\n",
       "      <td>Olds</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "      <td>Bickle</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>Worley</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WOS:000088763200026</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Araujo</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WOS:000169285300025</td>\n",
       "      <td>1</td>\n",
       "      <td>ME</td>\n",
       "      <td>Inchiosa</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WOS:000169285300025</td>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "      <td>In</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id  author_seq_nr given_name family_name  corresponding  \\\n",
       "0  WOS:000075569500101              1         JL    Krichmar           True   \n",
       "1  WOS:000075569500101              2         GA      Ascoli          False   \n",
       "2  WOS:000075569500101              3         JL        Olds          False   \n",
       "3  WOS:000075569500101              4          L      Hunter          False   \n",
       "4  WOS:000086279300008              1          J      Bickle           True   \n",
       "5  WOS:000086279300008              2          C      Worley          False   \n",
       "6  WOS:000086279300008              3          M   Bernstein          False   \n",
       "7  WOS:000088763200026              1          S      Araujo           True   \n",
       "8  WOS:000169285300025              1         ME    Inchiosa           True   \n",
       "9  WOS:000169285300025              2          V          In          False   \n",
       "\n",
       "   aff_seq_nr organization wos_suborganization vendor_org_id  \n",
       "0         NaN          NaN                 NaN           NaN  \n",
       "1         NaN          NaN                 NaN           NaN  \n",
       "2         NaN          NaN                 NaN           NaN  \n",
       "3         NaN          NaN                 NaN           NaN  \n",
       "4         NaN          NaN                 NaN           NaN  \n",
       "5         NaN          NaN                 NaN           NaN  \n",
       "6         NaN          NaN                 NaN           NaN  \n",
       "7         NaN          NaN                 NaN           NaN  \n",
       "8         NaN          NaN                 NaN           NaN  \n",
       "9         NaN          NaN                 NaN           NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors = df_authors.drop(['scopus_alt_script_name', 'email', 'scopus_author_id', 'orcid'], axis=1) # Might want to add further columns to drop later, such as wos_suborganization\tvendor_org_id\n",
    "df_authors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New columns are added to facilitate the cleaning process of the author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kleinow\\AppData\\Local\\Temp\\ipykernel_16292\\3945723719.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_authors['family_name_lower_wo_space'] = df_authors['family_name'].str.lower().str.replace(' ', '').str.replace('.', '').str.replace('-', '')  # Create a new column with lower case family names and remove ANY spaces from lower case family names\n",
      "C:\\Users\\kleinow\\AppData\\Local\\Temp\\ipykernel_16292\\3945723719.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_authors['given_name_lower_wo_space'] = df_authors['given_name'].str.lower().str.replace(' ', '').str.replace('.', '').str.replace('-', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>author_seq_nr</th>\n",
       "      <th>given_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>corresponding</th>\n",
       "      <th>aff_seq_nr</th>\n",
       "      <th>organization</th>\n",
       "      <th>wos_suborganization</th>\n",
       "      <th>vendor_org_id</th>\n",
       "      <th>family_name_lower_wo_space</th>\n",
       "      <th>given_name_lower_wo_space</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>1</td>\n",
       "      <td>JL</td>\n",
       "      <td>Krichmar</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>krichmar</td>\n",
       "      <td>jl</td>\n",
       "      <td>krichmar_jl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>2</td>\n",
       "      <td>GA</td>\n",
       "      <td>Ascoli</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ascoli</td>\n",
       "      <td>ga</td>\n",
       "      <td>ascoli_ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>3</td>\n",
       "      <td>JL</td>\n",
       "      <td>Olds</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>olds</td>\n",
       "      <td>jl</td>\n",
       "      <td>olds_jl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOS:000075569500101</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hunter</td>\n",
       "      <td>l</td>\n",
       "      <td>hunter_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "      <td>Bickle</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bickle</td>\n",
       "      <td>j</td>\n",
       "      <td>bickle_j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>Worley</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worley</td>\n",
       "      <td>c</td>\n",
       "      <td>worley_c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WOS:000086279300008</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>Bernstein</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bernstein</td>\n",
       "      <td>m</td>\n",
       "      <td>bernstein_m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WOS:000088763200026</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Araujo</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>araujo</td>\n",
       "      <td>s</td>\n",
       "      <td>araujo_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WOS:000169285300025</td>\n",
       "      <td>1</td>\n",
       "      <td>ME</td>\n",
       "      <td>Inchiosa</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inchiosa</td>\n",
       "      <td>me</td>\n",
       "      <td>inchiosa_me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WOS:000169285300025</td>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "      <td>In</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>v</td>\n",
       "      <td>in_v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id  author_seq_nr given_name family_name  corresponding  \\\n",
       "0  WOS:000075569500101              1         JL    Krichmar           True   \n",
       "1  WOS:000075569500101              2         GA      Ascoli          False   \n",
       "2  WOS:000075569500101              3         JL        Olds          False   \n",
       "3  WOS:000075569500101              4          L      Hunter          False   \n",
       "4  WOS:000086279300008              1          J      Bickle           True   \n",
       "5  WOS:000086279300008              2          C      Worley          False   \n",
       "6  WOS:000086279300008              3          M   Bernstein          False   \n",
       "7  WOS:000088763200026              1          S      Araujo           True   \n",
       "8  WOS:000169285300025              1         ME    Inchiosa           True   \n",
       "9  WOS:000169285300025              2          V          In          False   \n",
       "\n",
       "   aff_seq_nr organization wos_suborganization vendor_org_id  \\\n",
       "0         NaN          NaN                 NaN           NaN   \n",
       "1         NaN          NaN                 NaN           NaN   \n",
       "2         NaN          NaN                 NaN           NaN   \n",
       "3         NaN          NaN                 NaN           NaN   \n",
       "4         NaN          NaN                 NaN           NaN   \n",
       "5         NaN          NaN                 NaN           NaN   \n",
       "6         NaN          NaN                 NaN           NaN   \n",
       "7         NaN          NaN                 NaN           NaN   \n",
       "8         NaN          NaN                 NaN           NaN   \n",
       "9         NaN          NaN                 NaN           NaN   \n",
       "\n",
       "  family_name_lower_wo_space given_name_lower_wo_space         name  \n",
       "0                   krichmar                        jl  krichmar_jl  \n",
       "1                     ascoli                        ga    ascoli_ga  \n",
       "2                       olds                        jl      olds_jl  \n",
       "3                     hunter                         l     hunter_l  \n",
       "4                     bickle                         j     bickle_j  \n",
       "5                     worley                         c     worley_c  \n",
       "6                  bernstein                         m  bernstein_m  \n",
       "7                     araujo                         s     araujo_s  \n",
       "8                   inchiosa                        me  inchiosa_me  \n",
       "9                         in                         v         in_v  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'given_name' and 'family_name' to lowercase and remove spaces\n",
    "df_authors['family_name_lower_wo_space'] = df_authors['family_name'].str.lower().str.replace(' ', '').str.replace('.', '').str.replace('-', '')  # Create a new column with lower case family names and remove ANY spaces from lower case family names\n",
    "\n",
    "df_authors['given_name_lower_wo_space'] = df_authors['given_name'].str.lower().str.replace(' ', '').str.replace('.', '').str.replace('-', '') \n",
    "\n",
    "\n",
    "df_authors['name'] = df_authors['family_name_lower_wo_space'] + \"_\" + df_authors['given_name_lower_wo_space'] # Create a new column with the lower case family names and given names combined\n",
    "\n",
    "df_authors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I am sorting the column name in alphabetical order to detect misspellings in the author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>author_seq_nr</th>\n",
       "      <th>given_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>corresponding</th>\n",
       "      <th>aff_seq_nr</th>\n",
       "      <th>organization</th>\n",
       "      <th>wos_suborganization</th>\n",
       "      <th>vendor_org_id</th>\n",
       "      <th>family_name_lower_wo_space</th>\n",
       "      <th>given_name_lower_wo_space</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>WOS:000248868800018</td>\n",
       "      <td>4</td>\n",
       "      <td>Henry D. I.</td>\n",
       "      <td>Abarbanel</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abarbanel</td>\n",
       "      <td>henrydi</td>\n",
       "      <td>abarbanel_henrydi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>WOS:000300904900019</td>\n",
       "      <td>3</td>\n",
       "      <td>Abdolhossein</td>\n",
       "      <td>Abbassian</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Inst Res Fundamental Sci IPM\"}</td>\n",
       "      <td>{\"Sch Math\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abbassian</td>\n",
       "      <td>abdolhossein</td>\n",
       "      <td>abbassian_abdolhossein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>WOS:000374840600024</td>\n",
       "      <td>5</td>\n",
       "      <td>David F.</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{\"Univ Melbourne\"}</td>\n",
       "      <td>{\"Florey Dept Neurosci &amp; Mental Hlth\"}</td>\n",
       "      <td>{\"University of Melbourne\"}</td>\n",
       "      <td>abbott</td>\n",
       "      <td>davidf</td>\n",
       "      <td>abbott_davidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>WOS:000374840600024</td>\n",
       "      <td>5</td>\n",
       "      <td>David F.</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{\"Univ Melbourne\"}</td>\n",
       "      <td>{\"Dept Med\"}</td>\n",
       "      <td>{\"University of Melbourne\"}</td>\n",
       "      <td>abbott</td>\n",
       "      <td>davidf</td>\n",
       "      <td>abbott_davidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>WOS:000374840600024</td>\n",
       "      <td>5</td>\n",
       "      <td>David F.</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Florey Inst Neurosci &amp; Mental Hlth\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"Florey Institute of Neuroscience &amp; Mental He...</td>\n",
       "      <td>abbott</td>\n",
       "      <td>davidf</td>\n",
       "      <td>abbott_davidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>WOS:000890970400010</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jia Xiao-Li</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Tianjin Univ\"}</td>\n",
       "      <td>{\"Acad Med Engn &amp; Translat Med\"}</td>\n",
       "      <td>{\"Tianjin University\"}</td>\n",
       "      <td>jiaxiaoli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>WOS:000890970400010</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hu Nan</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Tianjin Univ\"}</td>\n",
       "      <td>{\"Acad Med Engn &amp; Translat Med\"}</td>\n",
       "      <td>{\"Tianjin University\"}</td>\n",
       "      <td>hunan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>WOS:000890970400010</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wang You-Wei</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Tianjin Univ\"}</td>\n",
       "      <td>{\"Acad Med Engn &amp; Translat Med\"}</td>\n",
       "      <td>{\"Tianjin University\"}</td>\n",
       "      <td>wangyouwei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>WOS:000890970400010</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Li Xiao-Hong</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"Tianjin Univ\"}</td>\n",
       "      <td>{\"Acad Med Engn &amp; Translat Med\"}</td>\n",
       "      <td>{\"Tianjin University\"}</td>\n",
       "      <td>lixiaohong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>WOS:000294241800004</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liu Li</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liuli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7471 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id  author_seq_nr    given_name   family_name  \\\n",
       "5102  WOS:000248868800018              4   Henry D. I.     Abarbanel   \n",
       "4440  WOS:000300904900019              3  Abdolhossein     Abbassian   \n",
       "3827  WOS:000374840600024              5      David F.        Abbott   \n",
       "3828  WOS:000374840600024              5      David F.        Abbott   \n",
       "3826  WOS:000374840600024              5      David F.        Abbott   \n",
       "...                   ...            ...           ...           ...   \n",
       "6564  WOS:000890970400010              1           NaN   Jia Xiao-Li   \n",
       "6565  WOS:000890970400010              2           NaN        Hu Nan   \n",
       "6566  WOS:000890970400010              3           NaN  Wang You-Wei   \n",
       "6567  WOS:000890970400010              4           NaN  Li Xiao-Hong   \n",
       "6727  WOS:000294241800004              1           NaN        Liu Li   \n",
       "\n",
       "      corresponding  aff_seq_nr                            organization  \\\n",
       "5102          False         NaN                                     NaN   \n",
       "4440          False         1.0        {\"Inst Res Fundamental Sci IPM\"}   \n",
       "3827          False         2.0                      {\"Univ Melbourne\"}   \n",
       "3828          False         4.0                      {\"Univ Melbourne\"}   \n",
       "3826          False         1.0  {\"Florey Inst Neurosci & Mental Hlth\"}   \n",
       "...             ...         ...                                     ...   \n",
       "6564          False         1.0                        {\"Tianjin Univ\"}   \n",
       "6565          False         1.0                        {\"Tianjin Univ\"}   \n",
       "6566          False         1.0                        {\"Tianjin Univ\"}   \n",
       "6567           True         1.0                        {\"Tianjin Univ\"}   \n",
       "6727           True         NaN                                     NaN   \n",
       "\n",
       "                         wos_suborganization  \\\n",
       "5102                                     NaN   \n",
       "4440                            {\"Sch Math\"}   \n",
       "3827  {\"Florey Dept Neurosci & Mental Hlth\"}   \n",
       "3828                            {\"Dept Med\"}   \n",
       "3826                                     NaN   \n",
       "...                                      ...   \n",
       "6564        {\"Acad Med Engn & Translat Med\"}   \n",
       "6565        {\"Acad Med Engn & Translat Med\"}   \n",
       "6566        {\"Acad Med Engn & Translat Med\"}   \n",
       "6567        {\"Acad Med Engn & Translat Med\"}   \n",
       "6727                                     NaN   \n",
       "\n",
       "                                          vendor_org_id  \\\n",
       "5102                                                NaN   \n",
       "4440                                                NaN   \n",
       "3827                        {\"University of Melbourne\"}   \n",
       "3828                        {\"University of Melbourne\"}   \n",
       "3826  {\"Florey Institute of Neuroscience & Mental He...   \n",
       "...                                                 ...   \n",
       "6564                             {\"Tianjin University\"}   \n",
       "6565                             {\"Tianjin University\"}   \n",
       "6566                             {\"Tianjin University\"}   \n",
       "6567                             {\"Tianjin University\"}   \n",
       "6727                                                NaN   \n",
       "\n",
       "     family_name_lower_wo_space given_name_lower_wo_space  \\\n",
       "5102                  abarbanel                   henrydi   \n",
       "4440                  abbassian              abdolhossein   \n",
       "3827                     abbott                    davidf   \n",
       "3828                     abbott                    davidf   \n",
       "3826                     abbott                    davidf   \n",
       "...                         ...                       ...   \n",
       "6564                  jiaxiaoli                       NaN   \n",
       "6565                      hunan                       NaN   \n",
       "6566                 wangyouwei                       NaN   \n",
       "6567                 lixiaohong                       NaN   \n",
       "6727                      liuli                       NaN   \n",
       "\n",
       "                        name  \n",
       "5102       abarbanel_henrydi  \n",
       "4440  abbassian_abdolhossein  \n",
       "3827           abbott_davidf  \n",
       "3828           abbott_davidf  \n",
       "3826           abbott_davidf  \n",
       "...                      ...  \n",
       "6564                     NaN  \n",
       "6565                     NaN  \n",
       "6566                     NaN  \n",
       "6567                     NaN  \n",
       "6727                     NaN  \n",
       "\n",
       "[7471 rows x 12 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort df_authors by the 'name' column\n",
    "df_authors_sorted = df_authors.sort_values(by='name')\n",
    "\n",
    "pd.set_option('display.max_rows', 10) # For full display of rows\n",
    "\n",
    "df_authors_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1331"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate full names by considering both 'given_name_lower_wo_space' and 'family_name_lower_wo_space'\n",
    "unique_authors = df_authors.drop_duplicates(subset=['given_name_lower_wo_space', 'family_name_lower_wo_space'])\n",
    "\n",
    "# Group by 'family_name_lower_wo_space' and identify groups where 'given_name_lower_wo_space' has more than one unique entry\n",
    "grouped = unique_authors.groupby('family_name_lower_wo_space').filter(lambda x: x['given_name_lower_wo_space'].nunique() > 1)\n",
    "\n",
    "# Sort for easier inspection\n",
    "grouped_sorted = grouped.sort_values(by=['family_name_lower_wo_space', 'given_name_lower_wo_space'])\n",
    "\n",
    "grouped_sorted.to_csv('authors_grouped_sorted.csv', index=False)\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "#grouped_sorted.head(50)\n",
    "len(grouped_sorted) # 1331 authors with the same family name but different given names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4369"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors['name'].nunique() # 4369 unique names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that I am not able to detect possible name changes due to marriage or divorce, since this would need an immense amount of individual investigation time. This would often apply to female scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the names that are different due to several ways of abbreviating or missspellings, are standardized based on visual inspection and manual checking of the publications. If a full given name is available in the data, it is used to replace the abbreviated version. If no full given name is available, the abbreviated version is used. This is done to avoid the loss of information. No further justification for keeping a name is given if found to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary where keys are standardized names and values are lists of names to be replaced\n",
    "names_dict = {\n",
    "    'adamy_juergen': ['adamy_j'],\n",
    "    'adeli_hojjat': ['adeli_h'],\n",
    "    'aertsen_ad': ['aertsen_a'],\n",
    "    'aihara_kazuyuki': ['aihara_k'],\n",
    "    'alexandrov_alexandars' : ['alexandrov_as'],\n",
    "    'amari_shunichi': ['amari_s', 'amari_si'],\n",
    "    'anastasio_thomasj': ['anastasio_tj'],\n",
    "    'arbib_michaela': ['arbib_ma'],\n",
    "    'ascoli_giorgioa': ['ascoli_ga'],\n",
    "    'avery_michaelc': ['avery_michael'],\n",
    "    'bapi_rajus': ['bapi_rs'],\n",
    "    'barbieri_riccardo': ['barbieri_r'],\n",
    "    'bartol_thomasm': ['bartol_t'],\n",
    "    'beni_majiddavoody': ['beni_majidd'],\n",
    "    'best_janet': ['best_j'],\n",
    "    'billard_audeg': ['billard_a'],\n",
    "    'blackwell_kimt': ['blackwell_kt'],\n",
    "    'borisyuk_roman': ['borisyuk_r'],\n",
    "    'bottemanne_hugo': ['bottemanne_h'],\n",
    "    'bower_jamesm': ['bower_jm'],\n",
    "    'bressler_stevenl': ['bressler_steven'],\n",
    "    'brown_emeryn': ['brown_en'],\n",
    "    'brzychczy_stanislaw': ['brzychczy_s'],\n",
    "    'buckley_christopherl': ['buckley_cl'],\n",
    "    'cangelosi_angelo': ['cangelosi_a'],\n",
    "    'cannon_robertc': ['cannon_r', 'cannon_rc, cannon_robert'],\n",
    "    'carnevale_nicholast': ['carnevale_nt'],\n",
    "    'cessac_bruno.': ['cessac_b'],\n",
    "    'chatzikonstantis_georgios.': ['chatzikonstantis_g'],\n",
    "    'cheniaux_elie.': ['cheniaux_e'],\n",
    "    'choi_charlestm.': ['choi_ctm'],\n",
    "    'cleland_thomasa.': ['cleland_ta'],\n",
    "    'cocks_bernie.': ['cocks_b'],\n",
    "    'cofre_rodrigo.': ['cofre_r'],\n",
    "    'coombes_stephen.': ['coombes_s'],\n",
    "    'cornelis_hugo.': ['cornelis_h'],\n",
    "    'costa_lucianodaf.': ['costa_ld'],\n",
    "    'cox_davidd.': ['cox_david'],\n",
    "    'crook_sharonm.': ['crook_sharon'],\n",
    "    'd\\'angelo_egidio.': ['d\\'angelo_e'],\n",
    "    'dagher_alain.': ['dagher_a'],\n",
    "    'dahal_nabaraj.': ['dahal_n'],\n",
    "    'dasari_nagam': ['dasari_n', 'dasari_naga'],\n",
    "    'daskalova_mariyas.': ['daskalova_m', 'daskalova_mariya', 'daskalova_ms'],\n",
    "    'davison_andrewp': ['davison_ap'],\n",
    "    'deco_gustavo': ['deco_g'],\n",
    "    'dehaan_willem.': ['dehaan_w'],\n",
    "    'destexhe_alain': ['destexhe_a'],\n",
    "    'dezeeuw_chris': ['dezeeuw_c'],\n",
    "    'diesmann_markus': ['diesmann_m'],\n",
    "    'dillmann_ruediger': ['dillmann_rudiger'],\n",
    "    'dinkelbach_helgeuelo': ['dinkelbach_helgesue', 'dinkelbach_helgeulo'],\n",
    "    'dolan_raymondj': ['dolan_rj'],\n",
    "    'drakopoulos_georgios': ['drakopoulos_georgtos'],\n",
    "    'driesen_naomir': ['driesen_naomi'],\n",
    "    'ekeberg_orjan': ['ekeberg_o'],\n",
    "    'eppler_jochenmartin': ['eppler_jochen', 'eppler_jochenm'],\n",
    "    'erdi_peter': ['erdi_p'],\n",
    "    'espinosaramos_josafathi': ['espinosaramos_josafath'],\n",
    "    'fabietti_marcosi': ['fabietti_marcos'],\n",
    "    'fairhall_adriennel': ['fairhall_adrienne'],\n",
    "    'feng_jianfeng': ['feng_jf'],\n",
    "    'fletcher_paulc': ['fletcher_paul'],\n",
    "    'friston_karlj': ['friston_karl', 'friston_kj'],\n",
    "    'frith_chrisd': ['frith_chris'],\n",
    "    'furber_steveb': ['furber_steve'],\n",
    "    'gauld_christophe': ['gauld_c'],\n",
    "    'geminiani_alice': ['geminiani_a'],\n",
    "    'gerstner_wulfram': ['gerstner_w'],\n",
    "    'gewaltig_marcoliver': ['gewaltig_mo'],\n",
    "    'girard_benoit': ['girard_b'],\n",
    "    'giugliano_michele': ['giugliano_m'],\n",
    "    'gomi_hiroaki': ['gomi_h'],\n",
    "    'grayroncal_williamr': ['grayroncal_william'],\n",
    "    'guntu_vsk': ['guntu_vinay'],\n",
    "    'gurney_kevinn': ['gurney_k', 'gurney_kevin'],\n",
    "    'gutierrez_carlosenrique': ['gutierrez_carlos'],\n",
    "    'hamker_fredh': ['hamker_fh'],\n",
    "    'hasani_raminm': ['hasani_ramin'],\n",
    "    'hasselmo_michaele': ['hasselmo_me'],\n",
    "    'heckman_charlesjj': ['heckman_cj'],\n",
    "    'heinke_dietmar': ['heinke_d'],\n",
    "    'hines_michaell': ['hines_michael', 'hines_ml'],\n",
    "    'hopkins_michaelw': ['hopkins_michael'],\n",
    "    'howell_fredrickw': ['howell_f'],\n",
    "    'huys_quentinjm': ['huys_qjm'],\n",
    "    'jin_rong': ['jin_r'],\n",
    "    'jirsa_viktork': ['jirsa_viktor'],\n",
    "    'jolivet_renaudb': ['jolivet_renaud'],\n",
    "    'kawato_mitsuo': ['kawato_m'],\n",
    "    'kay_kendrickn': ['kay_kendrick'],\n",
    "    'king_jamesgonzalo': ['king_jamesg'],\n",
    "    'kohn_andrefabio': ['kohn_andre', 'kohn_andref'],\n",
    "    'kording_konradp': ['kording_k'],\n",
    "    'krichmar_jeffreyl': ['krichmar_jl'],\n",
    "    'kringelbach_mortenll': ['kringelbach_mortenl'],\n",
    "    'krustev_stefan': ['krustev_sm'],\n",
    "    'krystal_johnh': ['krystal_john'],\n",
    "    'kunkel_susanne': ['kunkel_s'],\n",
    "    'lai_weidian': ['lai_wd'],\n",
    "    'lankarany_milad': ['lankarany_m'],\n",
    "    'lansner_anders': ['lansner_a'],\n",
    "    'levin_michael': ['levin_m'],\n",
    "    'lin_kevink': ['lin_kk'],\n",
    "    'linster_christiane': ['linster_c'],\n",
    "    'lomakina_ekaterinai': ['lomakina_ekaterina'],\n",
    "    'maass_wolfgang': ['maass_w'],\n",
    "    'madureira_danieleqm': ['madureira_dqm'],\n",
    "    'marenco_luis': ['marenco_l'],\n",
    "    'mcginnity_tmartin': ['mcginnity_tm'],\n",
    "    'mcintosh_anthonyrandal': ['mcintosh_anthonyr'],\n",
    "    'migliore_michele': ['migliore_m'],\n",
    "    'miller_johnp': ['miller_jp'],\n",
    "    'mladenov_mitko': ['mladenov_m'],\n",
    "    'morie_takashi': ['morie_t'],\n",
    "    'morrison_abigail': ['morrison_a'],\n",
    "    'morse_thomasm': ['morse_t', 'morse_tm'],\n",
    "    'moutoussis_michael': ['moutoussis_m'],\n",
    "    'movellan_jr': ['movellan_j'],\n",
    "    'mukherjee_pratik': ['mukherjee_p'],\n",
    "    'murray_johnd': ['murray_john'],\n",
    "    'nageswaran_jayrammoorkanikara': ['nageswaran_jayramm'],\n",
    "    'nair_satishs': ['nair_ss'],\n",
    "    'nandagopal_d(nanda)': ['nandagopal_d', 'nandagopal_nanda(d)'],\n",
    "    'nawrot_martinpaul': ['nawrot_martinp'],\n",
    "    'neftci_emreo': ['neftci_emre'],\n",
    "    'negrello_mario': ['negrello_m'],\n",
    "    'nijhout_hfrederik': ['nijhout_hf'],\n",
    "    'noelle_davidc': ['noelle_d', 'noelle_dc'],\n",
    "    'olds_jamesleland': ['olds_jl'],\n",
    "    'oweiss_karimg': ['oweiss_k', 'oweiss_karim'],\n",
    "    'parisi_domenico': ['parisi_d'],\n",
    "    'patel_mainakj': ['patel_mainak'],\n",
    "    'pearce_tc': ['pearce_t'],\n",
    "    'pedrocchi_alessandra': ['pedrocchi_a'],\n",
    "    'pedroni_brunou': ['pedroni_bruno'],\n",
    "    'pezzulo_giovanni': ['pezzulo_g'],\n",
    "    'pfister_jeanpascal': ['pfister_jp'],\n",
    "    'phillips_joshual': ['phillips_jl', 'phillips_joshua'],\n",
    "    'pillow_jonathanw': ['pillow_jonathan'],\n",
    "    'poggio_tomasoa': ['poggio_tomaso'],\n",
    "    'ponce_seanr': ['ponce_sean'],\n",
    "    'poznanski_romanr': ['poznanski_rr'],\n",
    "    'principe_josec': ['principe_jc'],\n",
    "    'rajendran_arathig': ['rajendran_arathi'],\n",
    "    'ramasamy_vijayalaxmi': ['ramasamy_vijayalakshmi'],\n",
    "    'rangan_aadityav': ['rangan_aaditya'],\n",
    "    'read_jennyca': ['read_jca'],\n",
    "    'reed_michaelc': ['reed_m'],\n",
    "    'richmond_paul': ['richmond_p'],\n",
    "    'riesenhuber_maximilian': ['riesenhuber_m'],\n",
    "    'rolls_edmundt': ['rolls_et'],\n",
    "    'roque_antonioc': ['roque_cantonio'],\n",
    "    'rosas_fernandoee': ['rosas_fernando'],\n",
    "    'rougier_nicolasp': ['rougier_nicolas'],\n",
    "    'rowley_andrewg': ['rowley_andrew'],\n",
    "    'sanjuan_miguelaf': ['sanjuan_maf'],\n",
    "    'santiago_robertoa': ['santiago_ra'],\n",
    "    'saykin_andrewj': ['saykin_a', 'saykin_andrew'],\n",
    "    'sboev_alexander': ['sboev_aleksandr'],\n",
    "    'schyns_philippeg': ['schyns_pg'],\n",
    "    'sejnowski_terrencej': ['sejnowski_t', 'sejnowski_terrence', 'sejnowski_tj'],\n",
    "    'shadmehr_reza': ['shadmehr_r'],\n",
    "    'sheabrown_eric': ['sheabrown_e'],\n",
    "    'shen_li': ['shen_l'],\n",
    "    'shepherd_gordonmg': ['shepherd_gm', 'shepherd_gordonm'],\n",
    "    'sidiropoulos_harry': ['sidiropoulos_h'],\n",
    "    'singh_nandinichatterjee': ['singh_nc'],\n",
    "    'skinner_francesk': ['skinner_frances'],\n",
    "    'smaragdos_georgios': ['smaragdos_g', 'smaragdos_george'],\n",
    "    'soltesz_ivan': ['soltesz_i'],\n",
    "    'sommeijer_bp': ['sommeijer_b'],\n",
    "    'soudris_dimitrios': ['soudris_dj'],\n",
    "    'stephan_klaasenno': ['stephan_klaase'],\n",
    "    'stephanova_dianai': ['stephanova_di', 'stephanova_diana'],\n",
    "    'stiles_joelr': ['stiles_j'],\n",
    "    'strydis_christos': ['strydis_c'],\n",
    "    'suhail_yasir': ['suhail_y'],\n",
    "    'surace_simonecarloj': ['surace_simonecarlo'],\n",
    "    'szczecinski_nicholass': ['szczecinski_nicholas'],\n",
    "    'tapson_jonathan': ['tapson_j'],\n",
    "    'taylor_briank': ['taylor_brian'],\n",
    "    'tegner_jespern': ['tegner_jesper'],\n",
    "    'thagard_paul': ['thagard_p'],\n",
    "    'thakur_chetansingh': ['thakur_chetans'],\n",
    "    'thoroughman_kurtaa': ['thoroughman_ka'],\n",
    "    'truccolo_wilson': ['truccolo_wa'],\n",
    "    'usui_shiro': ['usui_s'],\n",
    "    'valiant_leslieg': ['valiant_lg'],\n",
    "    'vanalbada_sachaj': ['vanalbada_sacha', 'vanalbada_sj'],\n",
    "    'vangerven_marcelaj': ['vangerven_marcel'],\n",
    "    'vanschaik_andre': ['vanschaik_a'],\n",
    "    'verschure_pfmj': ['verschure_p', 'verschure_paul'],\n",
    "    'vijayalakshmi_ramasamy': ['vijayalakshmi_r'],\n",
    "    'villa_alessandroep': ['villa_aep'],\n",
    "    'voutsas_kyriakos': ['voutsas_k'],\n",
    "    'wang_runchunm': ['wang_runchun'],\n",
    "    'wendling_fabrice': ['wendling_f'],\n",
    "    'west_john': ['west_j'],\n",
    "    'wester_brocka': ['wester_brock'],\n",
    "    'yang_genevievej': ['yang_genevieve'],\n",
    "    'yilmaz_ozgur': ['yilmaz_ozgor']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the dictionary to standardize names\n",
    "for correct_name, names_to_replace in names_dict.items():\n",
    "    df_authors.loc[df_authors['name'].isin(names_to_replace), 'name'] = correct_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4161"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors['name'].nunique() # 4161 unique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors.to_csv('cn_authors_clean.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
